{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BP+OSD: A decoder for quantum LDPC codes \n",
    "A Python library implementing belief propagation with ordered statistics post-processing for decoding sparse quantum LDPC codes as described in [arXiv:2005.07016](https://arxiv.org/abs/2005.07016). Note, this library has recently been completly rewritten using Python and Cython. The bulk of the code now resides in the [LDPC](https://github.com/quantumgizmos/ldpc) repository. The original C++ version can be found in the `cpp_version` branch of this repository.\n",
    "\n",
    "## Installation from PyPi (recommended method)\n",
    "\n",
    "Installation from [PyPi](https://pypi.org/project/bposd/) requires Python>=3.6.\n",
    "To install via pip, run:\n",
    "\n",
    "```\n",
    "pip install -U bposd\n",
    "```\n",
    "\n",
    "## Documentation\n",
    "This package buids upon the [LDPC](https://github.com/quantumgizmos/ldpc) python package. The documentation for LDPC can be found [here](https://roffe.eu/software/ldpc/index.html).\n",
    "\n",
    "## Attribution\n",
    "If you use this software in your research, please cite the following research paper:\n",
    "\n",
    "```\n",
    "@article{roffe_decoding_2020,\n",
    "   title={Decoding across the quantum low-density parity-check code landscape},\n",
    "   volume={2},\n",
    "   ISSN={2643-1564},\n",
    "   url={http://dx.doi.org/10.1103/PhysRevResearch.2.043423},\n",
    "   DOI={10.1103/physrevresearch.2.043423},\n",
    "   number={4},\n",
    "   journal={Physical Review Research},\n",
    "   publisher={American Physical Society (APS)},\n",
    "   author={Roffe, Joschka and White, David R. and Burton, Simon and Campbell, Earl},\n",
    "   year={2020},\n",
    "   month={Dec}\n",
    "}\n",
    "```\n",
    "\n",
    "Please also cite the LDPC software package:\n",
    "\n",
    "```\n",
    "@software{Roffe_LDPC_Python_tools_2022,\n",
    "author = {Roffe, Joschka},\n",
    "title = {{LDPC: Python tools for low density parity check codes}},\n",
    "url = {https://pypi.org/project/ldpc/},\n",
    "year = {2022}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage\n",
    "\n",
    "## Constructing CSS codes\n",
    "\n",
    "The `bposd.css.css_code` class can be used to create a CSS code from two classical codes. As an example, we can create a [[7,4,3]] Steane code from the classical Hamming code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hx\n",
      "[[0 0 0 1 1 1 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 0 1 0 1 0 1]]\n",
      "Hz\n",
      "[[0 0 0 1 1 1 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 0 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from ldpc.codes import hamming_code\n",
    "from bposd.css import css_code\n",
    "h=hamming_code(3) #Hamming code parity check matrix\n",
    "steane_code=css_code(hx=h,hz=h) #create Steane code where both hx and hz are Hamming codes\n",
    "print(\"Hx\")\n",
    "print(steane_code.hx)\n",
    "print(\"Hz\")\n",
    "print(steane_code.hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bposd.css.css_code` class automatically computes the logical operators of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lx Logical\n",
      "[[1 1 1 0 0 0 0]]\n",
      "Lz Logical\n",
      "[[1 1 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lx Logical\")\n",
    "print(steane_code.lx)\n",
    "print(\"Lz Logical\")\n",
    "print(steane_code.lz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all combinations of the `hx` and `hz` matrices will produce a valid CSS code. Use the `bposd.css.css_code.test` function to check whether the code is valid. For example, we can easily check that the Steane code passes all the CSS code tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Unnamed CSS code>, (3,4)-[[7,1,nan]]\n",
      " -Block dimensions: Pass\n",
      " -PCMs commute hz@hx.T==0: Pass\n",
      " -PCMs commute hx@hz.T==0: Pass\n",
      " -lx \\in ker{hz} AND lz \\in ker{hx}: Pass\n",
      " -lx and lz anticommute: Pass\n",
      " -<Unnamed CSS code> is a valid CSS code w/ params (3,4)-[[7,1,nan]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steane_code.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of a code that isn't valid, consider the case when `hx` and `hz` are repetition codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Unnamed CSS code>, (2,2)-[[7,-5,nan]]\n",
      " -Block dimensions incorrect\n",
      " -PCMs commute hz@hx.T==0: Fail\n",
      " -PCMs commute hx@hz.T==0: Fail\n",
      " -lx \\in ker{hz} AND lz \\in ker{hx}: Pass\n",
      " -lx and lz anitcommute: Fail\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ldpc.codes import rep_code\n",
    "\n",
    "hx=hz=rep_code(7)\n",
    "qcode=css_code(hx,hz)\n",
    "qcode.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypergraph product codes\n",
    "\n",
    "The hypergraph product can be used to construct a valid CSS code from any pair of classical seed codes. To use the the hypergraph product, call the `bposd.hgp.hgp` function. Below is an example of how the distance-3 surface code can be constructed by taking the hypergraph product of two distance-3 repetition codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Unnamed CSS code>, (2,4)-[[13,1,3]]\n",
      " -Block dimensions: Pass\n",
      " -PCMs commute hz@hx.T==0: Pass\n",
      " -PCMs commute hx@hz.T==0: Pass\n",
      " -lx \\in ker{hz} AND lz \\in ker{hx}: Pass\n",
      " -lx and lz anticommute: Pass\n",
      " -<Unnamed CSS code> is a valid CSS code w/ params (2,4)-[[13,1,3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ldpc.codes import rep_code\n",
    "from bposd.hgp import hgp\n",
    "h=rep_code(3)\n",
    "surface_code=hgp(h1=h,h2=h,compute_distance=True) #nb. set compute_distance=False for larger codes\n",
    "surface_code.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP+OSD Decoding\n",
    "\n",
    "BP+OSD decoding is useful for codes that do not perform well under standard-BP. To use the BP+OSD decoder, we first call the `bposd.bposd_decoder` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ldpc import bposd_decoder\n",
    "\n",
    "bpd=bposd_decoder(\n",
    "    surface_code.hz,#the parity check matrix\n",
    "    #hz1,\n",
    "    error_rate=0.05,\n",
    "    xyz_error_bias= [0, 0, 1],\n",
    "    channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter=surface_code.N, #the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=7 #the osd search depth\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ldpc import bposd_decoder\n",
    "\n",
    "bpd=bposd_decoder(\n",
    "    steane_code.hz,#the parity check matrix\n",
    "    #hz1,\n",
    "    error_rate=0.05,\n",
    "    xyz_error_bias= [0, 0, 1],\n",
    "    channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter=steane_code.N, #the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=4 #the osd search depth\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hx\n",
      "[[0 0 0 1 1 1 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 0 1 0 1 0 1]]\n",
      "Hz\n",
      "[[0 0 0 1 1 1 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 0 1 0 1 0 1]]\n",
      "[[0 0 0 1 1 1 1]\n",
      " [1 1 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from ldpc.codes import hamming_code\n",
    "from bposd.css import css_code\n",
    "h=hamming_code(3) #Hamming code parity check matrix\n",
    "steane_code=css_code(hx=h,hz=h) #create Steane code where both hx and hz are Hamming codes\n",
    "print(\"Hx\")\n",
    "print(steane_code.hx)\n",
    "print(\"Hz\")\n",
    "print(steane_code.hz)\n",
    "hz_s1 = steane_code.hz\n",
    "hz_s1[-2,:]=(hz_s1[-1,:]+hz_s1[-2,:])%2\n",
    "hz_s1[-1,:] = np.zeros(len(hz_s1[-1,:]))\n",
    "print(hz_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ldpc import bposd_decoder\n",
    "\n",
    "bpd=bposd_decoder(\n",
    "    hz_s1,#the parity check matrix\n",
    "    #hz1,\n",
    "    error_rate=0.05,\n",
    "    xyz_error_bias= [0, 0, 1],\n",
    "    channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter=steane_code.N, #the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=4 #the osd search depth\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]]\n",
      "[[1 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "h=hamming_code(3) #Hamming code parity check matrix\n",
    "steane_code=css_code(hx=h,hz=h)\n",
    "print(steane_code.lz)\n",
    "lz1 = steane_code.lz\n",
    "\n",
    "lz1[0][1] = 0\n",
    "lz1[0][2] = 0\n",
    "lz1[0][5] = 1\n",
    "lz1[0][6] = 1\n",
    "print(lz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0]\n",
      "[0 1 0]\n",
      "Error\n",
      "[1 0 0 0 0 0 0]\n",
      "BP+OSD Decoding\n",
      "[1 0 0 0 0 0 0]\n",
      "[[1 0 0 0 0 1 1]]\n",
      "[0]\n",
      "False\n",
      "Logical Error: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample the errors:\n",
    "\n",
    "# for one-layer 7 qubit:\n",
    "# combine the qubit loss\n",
    "# 2/3 * p\n",
    "\n",
    "# X and Z both\n",
    "\n",
    "# for multi-layer 7 qubit\n",
    "\n",
    "# for multi-layer 48 qubit\n",
    "\n",
    "error=np.zeros(steane_code.N).astype(int)\n",
    "print(error)\n",
    "error[[0]]=1\n",
    "print(error)\n",
    "syndrome=hz_s1@error %2\n",
    "#syndrome=steane_code.hz@error % 2\n",
    "print(syndrome)\n",
    "bpd.decode(syndrome)\n",
    "\n",
    "print(\"Error\")\n",
    "print(error)\n",
    "print(\"BP+OSD Decoding\")\n",
    "print(bpd.osdw_decoding)\n",
    "#Decoding is successful if the residual error commutes with the logical operators\n",
    "residual_error=(bpd.osdw_decoding+error) %2\n",
    "a=(lz1@residual_error%2).any()\n",
    "print(lz1)\n",
    "print((lz1@residual_error%2))\n",
    "print(a)\n",
    "if a: a=\"Yes\"\n",
    "else: a=\"No\"\n",
    "print(f\"Logical Error: {a}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BP+OSD decoding with a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sx_mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mldpc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bposd_decoder\n\u001b[1;32m     10\u001b[0m bpd\u001b[38;5;241m=\u001b[39mbposd_decoder(\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mSx_mat\u001b[49m,\u001b[38;5;66;03m#the parity check matrix\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     error_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m     13\u001b[0m     xyz_error_bias\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     14\u001b[0m     channel_probs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m], \u001b[38;5;66;03m#assign error_rate to each qubit. This will override \"error_rate\" input variable\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39msteane_code\u001b[38;5;241m.\u001b[39mN, \u001b[38;5;66;03m#the maximum number of iterations for BP)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     bp_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     ms_scaling_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;66;03m#min sum scaling factor. If set to zero the variable scaling factor method is used\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     osd_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mosd_cs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     osd_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m \u001b[38;5;66;03m#the osd search depth\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# sample the Pauli error:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m error\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(steane_code\u001b[38;5;241m.\u001b[39mN)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sx_mat' is not defined"
     ]
    }
   ],
   "source": [
    "# first for loop:\n",
    "# under one qubit loss case:\n",
    "# 1000 samples for pauli error?; 10000 samples for pauli error?\n",
    "# use Sx_mat and logicals (for the time being) to represent the remaining stabilizers/logical\n",
    "\n",
    "# define the \"BP+OSD\" decoder using the remaining Sx_mat\n",
    "import numpy as np\n",
    "from ldpc import bposd_decoder\n",
    "\n",
    "bpd=bposd_decoder(\n",
    "    Sx_mat,#the parity check matrix\n",
    "    error_rate=0.05,\n",
    "    xyz_error_bias= [1, 0, 0],\n",
    "    channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter=steane_code.N, #the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=4 #the osd search depth\n",
    "    )\n",
    "\n",
    "# sample the Pauli error:\n",
    "error=np.zeros(steane_code.N).astype(int)\n",
    "error[[0]]=1\n",
    "syndrome=Sx_mat @error %2\n",
    "#syndrome=steane_code.hz@error % 2\n",
    "bpd.decode(syndrome)\n",
    "#Decoding is successful if the residual error commutes with the logical operators\n",
    "residual_error=(bpd.osdw_decoding+error) %2\n",
    "a=(lz1@residual_error%2).any()\n",
    "if a: a=\"Yes\"\n",
    "else: a=\"No\"\n",
    "print(f\"Logical Error: {a}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Nrep = 1000\n",
    "# pauli error p we want to test\n",
    "p = 0.005\n",
    "for i_rep in range(Nrep):\n",
    "    error=np.zeros(steane_code.N).astype(int)\n",
    "    loss_inds = np.random.permutation(np.argwhere(np.random.rand(steane_code.N)<p)[:,0])\n",
    "    error[loss_inds] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 1 1]\n",
      " [1 1 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "[[1 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from ldpc.codes import hamming_code\n",
    "from bposd.css import css_code\n",
    "h=hamming_code(3) #Hamming code parity check matrix\n",
    "steane_code=css_code(hx=h,hz=h) #create Steane code where both hx and hz are Hamming codes\n",
    "hz_s1 = steane_code.hz\n",
    "hz_s1[-2,:]=(hz_s1[-1,:]+hz_s1[-2,:])%2\n",
    "hz_s1[-1,:] = np.zeros(len(hz_s1[-1,:]))\n",
    "h=hamming_code(3) #Hamming code parity check matrix\n",
    "steane_code=css_code(hx=h,hz=h)\n",
    "lz1 = steane_code.lz\n",
    "lz1[0][1] = 0\n",
    "lz1[0][2] = 0\n",
    "lz1[0][5] = 1\n",
    "lz1[0][6] = 1\n",
    "Sx_mat = hz_s1\n",
    "logicals = lz1\n",
    "print(Sx_mat)\n",
    "print(logicals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985\n",
      "0.02671527862548828\n"
     ]
    }
   ],
   "source": [
    "# then do the correction:\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# list the constant parameters: \n",
    "# 1. the number of samples for pauli errors (for each photon loss case): N_ps\n",
    "N_ps = 1000\n",
    "# 2. error rate of pauli errors:\n",
    "p_pauli = 0.005\n",
    "# 3. max number of iteratios for BP, set to be the number of physical qubits in the code\n",
    "N_iter = steane_code.N\n",
    "# 4. N_q: just the number of physical qubits in the code \n",
    "N_q = steane_code.N\n",
    "\n",
    "# add the loop outside that: which is the photon loss different cases\n",
    "\n",
    "# Ex1: give a specific Sx and logicals, feed into the Pauli error sample loop; test \n",
    "# 1.result stats 2. running time\n",
    "Sx_mat = hz_s1\n",
    "logicals = lz1\n",
    "N_pauli_succ = 0\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "bpd=bposd_decoder(\n",
    "    Sx_mat,#the parity check matrix\n",
    "    error_rate = 2/3*p_pauli,\n",
    "    xyz_error_bias= [1, 0, 0],\n",
    "    channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter = N_iter, #the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=4 #the osd search depth\n",
    "    )\n",
    "\n",
    "for i_rep in range(N_ps):\n",
    "    error=np.zeros(N_q).astype(int)\n",
    "    loss_inds = np.random.permutation(np.argwhere(np.random.rand(steane_code.N)<p_pauli)[:,0])\n",
    "    error[loss_inds] = 1\n",
    "    \n",
    "    syndrome=Sx_mat @error %2\n",
    "    #syndrome=steane_code.hz@error % 2\n",
    "    bpd.decode(syndrome)\n",
    "    #Decoding is successful if the residual error commutes with the logical operators\n",
    "    residual_error=(bpd.osdw_decoding+error) %2\n",
    "    # change \"lz1\" to logicals?\n",
    "    a = (logicals@residual_error%2).any()\n",
    "    if not a: \n",
    "        N_pauli_succ += 1\n",
    "\n",
    "p_pauli_succ = N_pauli_succ / N_ps\n",
    "    #if a: a=\"Yes\"\n",
    "    #else: a=\"No\"\n",
    "    #print(f\"Logical Error: {a}\\n\")\n",
    "    # add counting variable\n",
    "print(p_pauli_succ)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983\n",
      "0.012067079544067383\n"
     ]
    }
   ],
   "source": [
    "#one-layer steane code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.drawing.nx_agraph import write_dot, graphviz_layout\n",
    "import time\n",
    "from EffP import *\n",
    "from QLPDCgen import *\n",
    "from PLmatrix_CSS import *\n",
    "\n",
    "def succ_prob_css_calc_new(B_orig, logicals_in, s_nodes, loss_inds):\n",
    "    ######################################################\n",
    "    ## inputs:\n",
    "    ## B_orig [type: networkx]: stabilizer graph, two kinds of nodes: qubit 1...N and stabilizer s1...s_{Ns}\n",
    "    ## logicals_in [type: list of numpy arrays]: logical operators in every row, columns act on qubits\n",
    "    ## s_nodes [type: list]: list of stabilizer nodes s1...s_{Ns}\n",
    "    ## loss_inds [type: numpy array]: index of erased qubits\n",
    "    #####################\n",
    "    ## output:\n",
    "    ## succ_fail [type: binary value]: 0 (failure), 1(success)\n",
    "    ######################################################\n",
    "    N = np.size(logicals_in,1)\n",
    "    B = B_orig.copy()\n",
    "    logicals = list(np.copy(logicals_in))\n",
    "    s_nodes_set = set(np.copy(s_nodes))\n",
    "\n",
    "    Ns_remain = len(s_nodes_set) # number of stabilizer generators\n",
    "    q_remain = list(set(B.nodes())-s_nodes_set) # number of qubits (anciall+data)\n",
    "    node_list = list(s_nodes_set) + q_remain  # indices of all nodes in graph\n",
    "    adj_mat_new = nx.to_numpy_array(B, nodelist = node_list) # adjaceny matrix of stabilizer graph\n",
    "    Sx_mat = adj_mat_new[:Ns_remain,Ns_remain:] # stabilizer group matrix\n",
    "\n",
    "    for i_q, q in enumerate(loss_inds):\n",
    "        ## correct logical operators\n",
    "        logicals = correct_logical(q,logicals, Sx_mat)\n",
    "        ## update stabilizer group\n",
    "        ## first: update graph\n",
    "        if q in B:\n",
    "            B, s_nodes_set = modify_graph(q,B,s_nodes_set)\n",
    "        ## second: update stabilizer group matrix\n",
    "            Ns_remain = len(s_nodes_set)\n",
    "            if Ns_remain> 0:\n",
    "                q_remain = list(set(B.nodes())-s_nodes_set)\n",
    "                node_list = list(s_nodes_set) + q_remain\n",
    "                adj_mat_new = nx.to_numpy_matrix(B, nodelist = node_list)\n",
    "                Sx_red = adj_mat_new[:Ns_remain,Ns_remain:]\n",
    "                Sx_mat = np.zeros((Ns_remain,N))\n",
    "                Sx_mat[:,q_remain] = Sx_red\n",
    "            else:\n",
    "                Sx_mat = []\n",
    "                # break\n",
    "    num_qs = 0\n",
    "    if len(logicals)>=1:\n",
    "        for i_l in range(len(logicals)):\n",
    "            if np.sum(logicals[i_l][loss_inds])==0:\n",
    "                num_qs += 1 \n",
    "            # print(logicals)\n",
    "    return num_qs, Sx_mat, logicals\n",
    "\n",
    "# then do the correction:\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# list the constant parameters: \n",
    "# 1. the number of samples for pauli errors (for each photon loss case): N_ps\n",
    "N_ps = 1000\n",
    "# 2. error rate of pauli errors:\n",
    "p_pauli = 0.005\n",
    "# 3. max number of iteratios for BP, set to be the number of physical qubits in the code\n",
    "N_iter = steane_code.N\n",
    "# 4. N_q: just the number of physical qubits in the code \n",
    "N_q = steane_code.N\n",
    "\n",
    "# add the loop outside that: which is the photon loss different cases\n",
    "\n",
    "Sx_mat = hz_s1\n",
    "logicals = lz1\n",
    "N_pauli_succ = 0\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "bpd=bposd_decoder(\n",
    "    Sx_mat,#the parity check matrix\n",
    "    error_rate = 2/3*p_pauli,\n",
    "    xyz_error_bias= [1, 0, 0],\n",
    "    channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter = N_iter, #the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=4 #the osd search depth\n",
    "    )\n",
    "\n",
    "for i_rep in range(N_ps):\n",
    "    error=np.zeros(N_q).astype(int)\n",
    "    loss_inds = np.random.permutation(np.argwhere(np.random.rand(steane_code.N)<p_pauli)[:,0])\n",
    "    error[loss_inds] = 1\n",
    "    \n",
    "    syndrome=Sx_mat @error %2\n",
    "    #syndrome=steane_code.hz@error % 2\n",
    "    bpd.decode(syndrome)\n",
    "    #Decoding is successful if the residual error commutes with the logical operators\n",
    "    residual_error=(bpd.osdw_decoding+error) %2\n",
    "    # change \"lz1\" to logicals?\n",
    "    a = (logicals@residual_error%2).any()\n",
    "    if not a: \n",
    "        N_pauli_succ += 1\n",
    "\n",
    "p_pauli_succ = N_pauli_succ / N_ps\n",
    "    #if a: a=\"Yes\"\n",
    "    #else: a=\"No\"\n",
    "    #print(f\"Logical Error: {a}\\n\")\n",
    "    # add counting variable\n",
    "print(p_pauli_succ)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L= 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'to_numpy_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 163\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m#results = Parallel(n_jobs=num_cores)(delayed(runner)(i_rep) for i_rep in range(repeat))\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 111\u001b[0m, in \u001b[0;36mrunner\u001b[0;34m(i_rep)\u001b[0m\n\u001b[1;32m    109\u001b[0m loss_inds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(np\u001b[38;5;241m.\u001b[39margwhere(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(N)\u001b[38;5;241m<\u001b[39mp_stab)[:,\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m#succ_prob_7_ml[i_p] += succ_prob_css_calc(B_orig, logical, s_nodes, loss_inds)\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m succ_prob_7_num, Sx_mat, logicals \u001b[38;5;241m=\u001b[39m \u001b[43msucc_prob_css_calc_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB_orig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_inds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m N_pauli_succ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    113\u001b[0m bpd\u001b[38;5;241m=\u001b[39mbposd_decoder(\n\u001b[1;32m    114\u001b[0m     Sx_mat,\u001b[38;5;66;03m#the parity check matrix\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     error_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mp_pauli,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     osd_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m \u001b[38;5;66;03m#the osd search depth\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[20], line 46\u001b[0m, in \u001b[0;36msucc_prob_css_calc_new\u001b[0;34m(B_orig, logicals_in, s_nodes, loss_inds)\u001b[0m\n\u001b[1;32m     44\u001b[0m q_remain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(B\u001b[38;5;241m.\u001b[39mnodes())\u001b[38;5;241m-\u001b[39ms_nodes_set)\n\u001b[1;32m     45\u001b[0m node_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(s_nodes_set) \u001b[38;5;241m+\u001b[39m q_remain\n\u001b[0;32m---> 46\u001b[0m adj_mat_new \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy_matrix\u001b[49m(B, nodelist \u001b[38;5;241m=\u001b[39m node_list)\n\u001b[1;32m     47\u001b[0m Sx_red \u001b[38;5;241m=\u001b[39m adj_mat_new[:Ns_remain,Ns_remain:]\n\u001b[1;32m     48\u001b[0m Sx_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((Ns_remain,N))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'to_numpy_matrix'"
     ]
    }
   ],
   "source": [
    "#one-layer steane code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.drawing.nx_agraph import write_dot, graphviz_layout\n",
    "import time\n",
    "from EffP import *\n",
    "from QLPDCgen import *\n",
    "from PLmatrix_CSS import *\n",
    "\n",
    "def succ_prob_css_calc_new(B_orig, logicals_in, s_nodes, loss_inds):\n",
    "    ######################################################\n",
    "    ## inputs:\n",
    "    ## B_orig [type: networkx]: stabilizer graph, two kinds of nodes: qubit 1...N and stabilizer s1...s_{Ns}\n",
    "    ## logicals_in [type: list of numpy arrays]: logical operators in every row, columns act on qubits\n",
    "    ## s_nodes [type: list]: list of stabilizer nodes s1...s_{Ns}\n",
    "    ## loss_inds [type: numpy array]: index of erased qubits\n",
    "    #####################\n",
    "    ## output:\n",
    "    ## succ_fail [type: binary value]: 0 (failure), 1(success)\n",
    "    ######################################################\n",
    "    N = np.size(logicals_in,1)\n",
    "    B = B_orig.copy()\n",
    "    logicals = list(np.copy(logicals_in))\n",
    "    s_nodes_set = set(np.copy(s_nodes))\n",
    "\n",
    "    Ns_remain = len(s_nodes_set) # number of stabilizer generators\n",
    "    q_remain = list(set(B.nodes())-s_nodes_set) # number of qubits (anciall+data)\n",
    "    node_list = list(s_nodes_set) + q_remain  # indices of all nodes in graph\n",
    "    adj_mat_new = nx.to_numpy_array(B, nodelist = node_list) # adjaceny matrix of stabilizer graph\n",
    "    Sx_mat = adj_mat_new[:Ns_remain,Ns_remain:] # stabilizer group matrix\n",
    "\n",
    "    for i_q, q in enumerate(loss_inds):\n",
    "        ## correct logical operators\n",
    "        logicals = correct_logical(q,logicals, Sx_mat)\n",
    "        ## update stabilizer group\n",
    "        ## first: update graph\n",
    "        if q in B:\n",
    "            B, s_nodes_set = modify_graph(q,B,s_nodes_set)\n",
    "        ## second: update stabilizer group matrix\n",
    "            Ns_remain = len(s_nodes_set)\n",
    "            if Ns_remain> 0:\n",
    "                q_remain = list(set(B.nodes())-s_nodes_set)\n",
    "                node_list = list(s_nodes_set) + q_remain\n",
    "                adj_mat_new = nx.to_numpy_matrix(B, nodelist = node_list)\n",
    "                Sx_red = adj_mat_new[:Ns_remain,Ns_remain:]\n",
    "                Sx_mat = np.zeros((Ns_remain,N))\n",
    "                Sx_mat[:,q_remain] = Sx_red\n",
    "            else:\n",
    "                Sx_mat = []\n",
    "                # break\n",
    "    num_qs = 0\n",
    "    if len(logicals)>=1:\n",
    "        for i_l in range(len(logicals)):\n",
    "            if np.sum(logicals[i_l][loss_inds])==0:\n",
    "                num_qs += 1 \n",
    "            # print(logicals)\n",
    "    return num_qs, Sx_mat, logicals\n",
    "\n",
    "# then do the correction:\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# list the constant parameters: \n",
    "# 1. the number of samples for pauli errors (for each photon loss case): N_ps\n",
    "N_ps = 1000\n",
    "# 2. error rate of pauli errors:\n",
    "p_pauli = 0.005\n",
    "# 3. max number of iteratios for BP, set to be the number of physical qubits in the code\n",
    "N_iter = steane_code.N\n",
    "# 4. N_q: just the number of physical qubits in the code \n",
    "N_q = steane_code.N\n",
    "\n",
    "# add the loop outside that: which is the photon loss different cases\n",
    "\n",
    "bdy = True ## boundary condition, true (obc), false(pbc)\n",
    "repeat = 100\n",
    "Nrep = 10000 # number of iterations\n",
    "Nl_list = np.arange(1,2,2)\n",
    "p_list = [0.1]\n",
    "\n",
    "# in layer stabilizer group\n",
    "Sx_mat0 = np.array([[1,1,1,1,0,0,0],\\\n",
    "              [1,1,0,0,1,1,0],\\\n",
    "              [1,0,1,0,1,0,1]])\n",
    "Nq_l = np.size(Sx_mat0,1) # number of data qubits per layer\n",
    "Ns_l = np.size(Sx_mat0,0) # number of stabilizers per layer\n",
    "\n",
    "for i_L, Nl in enumerate(Nl_list):\n",
    "    print(\"L= %d\" % (Nl))\n",
    "\n",
    "    N = Nl*(Nq_l+Ns_l)+Ns_l # number of data qubits\n",
    "    Ns = Nl*Ns_l # number of stabilizers\n",
    "    s_nodes = [\"s%d\" % s for s in np.arange(Ns)]\n",
    "\n",
    "    B_orig = foliated_graph(Sx_mat,s_nodes, Nl, bdy, \"even\")\n",
    "    logical = np.zeros((1,N))\n",
    "    for i_l in range(Nl):\n",
    "        logical[0,i_l*(Nq_l+Ns_l):i_l*(Nq_l+Ns_l)+Nq_l] = np.ones(Nq_l)\n",
    "\n",
    "    def runner(i_rep):\n",
    "        tic = time.time()\n",
    "\n",
    "        succ_prob_7_ml = np.zeros(len(p_list))\n",
    "        for i_p, p_r in enumerate(p_list):\n",
    "            p_stab = 1-(1-p_r)**0.5\n",
    "            for i_r in range(Nrep):\n",
    "                loss_inds = np.random.permutation(np.argwhere(np.random.rand(N)<p_stab)[:,0])\n",
    "                #succ_prob_7_ml[i_p] += succ_prob_css_calc(B_orig, logical, s_nodes, loss_inds)\n",
    "                succ_prob_7_num, Sx_mat, logicals = succ_prob_css_calc_new(B_orig, logical, s_nodes, loss_inds)\n",
    "                N_pauli_succ = 0\n",
    "                bpd=bposd_decoder(\n",
    "                    Sx_mat,#the parity check matrix\n",
    "                    error_rate = 2/3*p_pauli,\n",
    "                    xyz_error_bias= [1, 0, 0],\n",
    "                    channel_probs=[None], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "                    max_iter = N_iter, #the maximum number of iterations for BP)\n",
    "                    bp_method=\"ms\",\n",
    "                    ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "                    osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "                    osd_order=4 #the osd search depth\n",
    "                    )\n",
    "\n",
    "                for i_rep in range(N_ps):\n",
    "                    error=np.zeros(N_q).astype(int)\n",
    "                    loss_inds = np.random.permutation(np.argwhere(np.random.rand(steane_code.N)<p_pauli)[:,0])\n",
    "                    error[loss_inds] = 1\n",
    "\n",
    "                    syndrome=Sx_mat @error %2\n",
    "                    #syndrome=steane_code.hz@error % 2\n",
    "                    bpd.decode(syndrome)\n",
    "                    #Decoding is successful if the residual error commutes with the logical operators\n",
    "                    residual_error=(bpd.osdw_decoding+error) %2\n",
    "                    # change \"lz1\" to logicals?\n",
    "                    a = (logicals@residual_error%2).any()\n",
    "                    if not a: \n",
    "                        N_pauli_succ += 1\n",
    "\n",
    "                p_pauli_succ = N_pauli_succ / N_ps\n",
    "                    #if a: a=\"Yes\"\n",
    "                    #else: a=\"No\"\n",
    "                    #print(f\"Logical Error: {a}\\n\")\n",
    "                    # add counting variable\n",
    "                print(p_pauli_succ)\n",
    "                succ_prob_7_ml[i_p] += p_pauli_succ * succ_prob_7_num\n",
    "        succ_prob_7_ml /= Nrep\n",
    "\n",
    "        toc = time.time()\n",
    "        print(\"finished L = %d, r=%d in %.1f secs\" % (Nl,i_rep,toc-tic))\n",
    "\n",
    "        if bdy:\n",
    "            fname = \"data_fig2/7q/\" + \"even_Nl_%d_i_%d.npz\" % (Nl,i_rep)\n",
    "            # fname = \"data_7q/\" + \"even_Nl_%d_i_%d.npz\" % (Nl,i_rep)\n",
    "        else:\n",
    "            assert 0\n",
    "\n",
    "        np.savez(fname, succ_prob=succ_prob_7_ml, p_list=p_list, Nrep=Nrep)\n",
    "\n",
    "        return 0\n",
    "\n",
    "    #results = Parallel(n_jobs=num_cores)(delayed(runner)(i_rep) for i_rep in range(repeat))\n",
    "    results = runner(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-layer steane code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-layer 48q code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-layer 48q code\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6142264746c19ed83c77205cabd673f219a6c42e5018feead8b479e250bcad8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
